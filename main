import requests
from bs4 import BeautifulSoup
import json
import time
import pandas as pd



headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
e=[]
for x in range(1,4):
    html=requests.get('https://indien.ahk.de/membership/fmp-member-directory/page-'+str(x),headers=headers)






    soup= BeautifulSoup(html.content, 'html.parser')

    # print(soup.title)
    content=soup.find_all('tr',class_='tr-content')

    # print(content)





    for property in content:
        name=(property.find('a',class_='a-href-content-link').text)
        region=(property.find('td',class_='c-col-7').text)
        country=(property.find('td',class_='c-col-8').text)
        website=(property.find('td',class_='c-col-9').text)

   


        property_info={
            'name':name,
            'region':region,
            'country':country,
            'website':website
        }

        # print(property_info)

        property_info=dict(map(str.strip,x) for x in property_info.items()) 
        e.append(property_info)
    print(len(e))
    time.sleep(3)

df=pd.DataFrame(e)
print(df.head())

df.to_csv('companydata10.csv')


# https: // indien.ahk.de/membership/fmp-member-directory/page-7?tx_cpsfmp_companymainplugin % 5Bcontroller % 5D = Company & tx_cpsfmp_companymainplugin % 5Bpage % 5D = 5 & cHash = c0c1b98546eb0f6187cc22d70a558701  # jumptoresults





    


    
        

        
    
    






